{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LN-LazyReader: From Online Light Novels to Audiobooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple python notebook that scrapes light novel websites and converts data into audiobooks in .wav format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import subprocess\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from lxml.html.clean import Cleaner\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the value of root_url with the URL of one of the ligh novel chapters. \n",
    "# The program will attempt to download all chapters starting from the input URL.\n",
    "# To download the whole novel, use the URL of the first chapter.\n",
    "\n",
    "# Root url\n",
    "root_url = 'https://m.wuxiaworld.co/library-of-heaven-is-path/1108180.html'\n",
    "\n",
    "# Chapter of the root url\n",
    "current_chapter = 501\n",
    "\n",
    "# Number of chapters per file\n",
    "file_range = 5\n",
    "\n",
    "# Maximum chapters to download starting from root url. Set to None to download all the following chapters.\n",
    "max_chapters = None\n",
    "\n",
    "# Output directories. \n",
    "output_text_dir = 'ln_text'\n",
    "output_audio_dir = 'ln_audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to infer the light novel website being scraped\n",
    "\n",
    "def get_website(url, websites):\n",
    "    for website in websites:\n",
    "        if website in url:\n",
    "            return website\n",
    "    return None\n",
    "\n",
    "def get_base_url(url, pattern):\n",
    "    return re.findall(pattern, url)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create acronym from the title of the novel\n",
    "\n",
    "def get_novel_title(url, regex, acronym=False):\n",
    "    output = re.findall(regex, url)[0]\n",
    "    output = output.replace('-', '_')\n",
    "    output = output.replace(' ', '_')\n",
    "    if acronym:\n",
    "        output = ''.join(word[0] for word in output.split()).upper()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts the title, content and next chapter url of a light novel chapter given a url\n",
    "\n",
    "def crawl_chapter(url, base_url, content_marker, title_marker, next_marker, replace_filters, cleaner):\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Get light novel title\n",
    "    title = data.find(*title_marker).get_text()\n",
    "    title = title.encode('utf-8')\n",
    "\n",
    "    # Get light novel content\n",
    "    content = str(data.find(*content_marker))\n",
    "    content = cleaner.clean_html(content)\n",
    "    content = content[len('<div>'):-len('</div>')]\n",
    "    content = content.strip()\n",
    "    for i in replace_filters:\n",
    "        content = content.replace(i, replace_filters[i])\n",
    "    content = content.encode('utf-8')\n",
    "\n",
    "    # Get next chapter url\n",
    "    try:\n",
    "        next_url = data.find(*next_marker)['href']\n",
    "        if not 'http' in next_url:\n",
    "            next_url = base_url + next_url\n",
    "    except:\n",
    "        next_url = None\n",
    "    \n",
    "    return {'title': title, 'content': content, 'next': next_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_novel(url, base_url, content_marker, title_marker, next_marker,cleaner, replace_filters,\n",
    "                max_chapters=None, verbose=True):\n",
    "    \n",
    "    novel = []\n",
    "    next_url = url\n",
    "    counter = 0\n",
    "    pbar = tqdm(disable=not(verbose))\n",
    "    \n",
    "    while next_url:\n",
    "        if max_chapters and counter >= max_chapters: break\n",
    "        else: counter += 1\n",
    "\n",
    "        chapter = crawl_chapter(next_url, base_url=base_url, \n",
    "                      content_marker=content_marker, \n",
    "                      title_marker=title_marker, \n",
    "                      next_marker=next_marker,\n",
    "                      replace_filters=replace_filters,\n",
    "                      cleaner=cleaner)\n",
    "        \n",
    "        if chapter['content'] == b'None': break\n",
    "        \n",
    "        novel.append(chapter)\n",
    "        next_url = chapter['next']\n",
    "        pbar.set_description(chapter['title'].decode('utf-8'), refresh=True)\n",
    "        pbar.update()\n",
    "    \n",
    "    return novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saves the crawled chapters into text files.\n",
    "\n",
    "novel            : a list of chapters crawled using the crawl_novel method\n",
    "text_dir         : a path object that points to the output directory of create_text_files method\n",
    "current_chapter  : specify the chapter of the root URL to adjust the name of the output text file\n",
    "file_range       : specify the number of chapters per text file\n",
    "chapter_append     : text to include before each chapters\n",
    "chapter_splitter : text that separate each chapters when multiple chapters are present in a single file\n",
    "'''\n",
    "\n",
    "def create_text_files(novel, text_dir,\n",
    "                      current_chapter = 1,\n",
    "                      file_range = 1,\n",
    "                      chapter_append = '',\n",
    "                      novel_acronym = '',\n",
    "                      chapter_splitter = '\\n\\n\\n**********\\n\\n\\n'):\n",
    "    \n",
    "    chapter_append = chapter_append.encode('utf-8')\n",
    "    chapter_splitter = chapter_splitter.encode('utf-8')\n",
    "    total_file_count = (len(novel) + current_chapter) // file_range\n",
    "    last_chapter = (len(novel) + current_chapter - 1) % file_range\n",
    "    \n",
    "    for idx, i in tqdm(enumerate(range(current_chapter, len(novel) + current_chapter, file_range)), \n",
    "                       desc='Creating text files'):\n",
    "        if idx == total_file_count:\n",
    "            output_file = f'{novel_acronym}_{str(idx + 1).zfill(5)}_Chapter_{i}_to_{i + last_chapter - 1}.txt'\n",
    "        else:\n",
    "            output_file = f'{novel_acronym}_{str(idx + 1).zfill(5)}_Chapter_{i}_to_{i + file_range - 1}.txt'\n",
    "        \n",
    "        with open(text_dir / output_file, 'ab') as my_file:\n",
    "            for chapter in novel[i-current_chapter : (i-current_chapter) + file_range]:\n",
    "                my_file.write(chapter_append + chapter['title'] + b'\\n\\n')\n",
    "                my_file.write(chapter['content'])\n",
    "                my_file.write(chapter_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text files into audio files\n",
    "# Requires balabolka - command line utility (http://www.cross-plus-a.com/bconsole.htm)\n",
    "\n",
    "def create_audio_files(text_dir, audio_dir, voice_name='Zira', audio_format='mp3'):\n",
    "    for chapter in tqdm(text_dir.glob('*.txt'), desc='Creating audio files'):\n",
    "        audio_file = audio_dir / (str(chapter.name)[:-len('.txt')])\n",
    "        if audio_format == 'wav':\n",
    "            my_cmd = str(f'balcon -f \"{chapter}\" -w \"{audio_file}.wav\" -n \"{voice_name}\"')\n",
    "        else:\n",
    "            my_cmd = str(f'balcon -f {chapter} -n {voice_name} -o --raw | lame -r -s 16 -m m -h - {audio_file}.mp3')\n",
    "        subprocess.call(my_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Meta Filters\n",
    "\n",
    "A dictionary containing the filters used to scrape the different light novel websites.\n",
    "Each dictionary keys refers to the name of the target light novel website for web scaping.\n",
    "Each item contains another dictionary containing the specific filters for the target website:\n",
    "    base_url : regex to capture the URL of the specific novel\n",
    "    title    : tuple required to capture the chapter title\n",
    "    content  : tuple required to capture the light novel content\n",
    "    next     : tuple required to capture the URL of the next chapter of the novel\n",
    "Values for title, content and next requires some basic understanding of the Beautiful Soup module\n",
    "as the tuples provided will be passed to the find(...) method of a BeautifulSoup object.\n",
    "\n",
    "'''\n",
    "\n",
    "meta_filters = {\n",
    "    'm.wuxiaworld': {\n",
    "        'base_url': r'https://m.wuxiaworld.co/.*/',\n",
    "        'acronym' : r'(?<=https://m.wuxiaworld.co/).*(?=/)',\n",
    "        'title': ('span', {'class': 'title'}),\n",
    "        'content': ('div', {'id': 'chaptercontent'}),\n",
    "        'next': ('a', {'id': 'pt_next'})\n",
    "    },\n",
    "    'royalroad': {\n",
    "        'base_url': r'^https://www.royalroad.com/',\n",
    "        'acronym' : r'(?<=https://www.royalroad.com/fiction/\\d{5}/).*(?=/chapter/\\d)',\n",
    "        'title': ('title',),\n",
    "        'content': ('div', {'class': 'chapter-inner chapter-content'}),\n",
    "        'next': ('link', {'rel': 'next'})\n",
    "    },\n",
    "}\n",
    "\n",
    "replace_filters = {\n",
    "    '<br>': '\\n',\n",
    "    '“': '\"',\n",
    "    '”': '\"',\n",
    "    '’': \"'\",\n",
    "    '‘': \"'\",\n",
    "    '《': '',\n",
    "    '》': '',\n",
    "    '…': '...',\n",
    "}\n",
    "\n",
    "# List of html tags to remove including contents\n",
    "kill_tags = ['ins']\n",
    "\n",
    "# List of html tags to remove excluding contents\n",
    "remove_tags = ['div', 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = get_website(root_url, meta_filters.keys())\n",
    "base_url = get_base_url(root_url, meta_filters[website]['base_url'])\n",
    "content_marker = meta_filters[website]['content']\n",
    "title_marker = meta_filters[website]['title']\n",
    "next_marker = meta_filters[website]['next']\n",
    "\n",
    "novel_title = get_novel_title(root_url, meta_filters[website]['acronym'], acronym=False)\n",
    "novel_acronym = get_novel_title(root_url, meta_filters[website]['acronym'], acronym=True)\n",
    "\n",
    "output_dir = Path(novel_title)\n",
    "text_dir = novel_title / Path(output_text_dir)\n",
    "audio_dir = novel_title / Path(output_audio_dir)\n",
    "\n",
    "# If directory exists, create a new one\n",
    "cnt = 0\n",
    "while text_dir.exists() or audio_dir.exists():\n",
    "    cnt += 1\n",
    "    text_dir = novel_title / Path(f'{output_text_dir}_{cnt}' )\n",
    "    audio_dir = novel_title / Path(f'{output_audio_dir}_{cnt}')\n",
    "\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "text_dir.mkdir(exist_ok=True)\n",
    "audio_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaner object\n",
    "cleaner = Cleaner(page_structure=False)\n",
    "cleaner.kill_tags = kill_tags\n",
    "cleaner.remove_tags = remove_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdba07a45d1449da8de0835149174af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the crawled data to a dictionary\n",
    "novel = crawl_novel(root_url, base_url=base_url, \n",
    "                    content_marker=content_marker, \n",
    "                    title_marker=title_marker, \n",
    "                    next_marker=next_marker,\n",
    "                    replace_filters=replace_filters,\n",
    "                    cleaner=cleaner,\n",
    "                    max_chapters=max_chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3cc413bfb5471e88c22250c3bd71a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Creating text files', max=1, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the crawled data into text files\n",
    "create_text_files(novel, text_dir=text_dir, file_range=file_range, \n",
    "                  current_chapter=current_chapter, \n",
    "                  novel_acronym = novel_acronym,\n",
    "                  chapter_append='Chapter ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dafc50399149d5ad27ab275d7d2575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Creating audio files', max=1, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert text files into audio files\n",
    "create_audio_files(text_dir=text_dir, audio_dir=audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
